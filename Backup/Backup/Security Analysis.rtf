{\rtf1\ansi\ansicpg1252\deff0\deflang1033{\fonttbl{\f0\fswiss\fcharset0 Arial;}{\f1\fmodern\fprq1\fcharset0 Lucida Console;}}
{\*\generator Msftedit 5.41.15.1515;}\viewkind4\uc1\pard\b\f0\fs20 Security Analysis and Audit - Backup Tool\b0\par
\par
Written by Thomas R. Lawrence\par
4 August 2014\par
\par
\par
\b I. Introduction\b0\par
\par
\i Backup\i0  (in this document, generally referred to as "the tool") is a simple archiving tool with with features designed to provide secure encryption of data sufficient for use with online storage systems (e.g. Google Drive, Dropbox, and others), wherein files may be archived with encryption to ensure that any adversaries cannot access the data (adversaries being one of: the cloud storage provider itself, attackers who compromise the cloud storage service, or attackers who interfere with the commuications between the user's computer and the cloud storage service).\par
\par
The program provides several loosely related functions:\par
1. A decremental archiving mode which maintains checkpoints of stored data. Each new checkpoint involves copying new or modified files. The most recent checkpoint is always a copy of the source file hierarchy. Earlier checkpoints contain differences.\par
2. A facility for bidirectionally synchronizing two file hierarchies.\par
3. A tar-like mode that packages a file hierarchy into a single file archive\par
4. A tar-like mode, called "dynamic pack", which maintains an archive as a set of segments. The archive can be updated, wherein new or modified files are incorporated into the aggregate archive and old files are removed. Only segments affected by changes are modified, allowing only a subset of the segment files to be synchronized with the online storage system. The segment size target is configurable, allowing granularity of online synchronization (efficiency) to be balanced against the number of individual segments.\par
\par
The program provides both data compression and encryption. Both are implemented as independent file container formats which are uniform across the application and can be selected independently. In particular, the encrypted container is the same for individual files or segments of an archive, and can be removed or added independently by a command line option.\par
\par
The program is intended to be operated as a command line tool (possibly in conjunction with shell scripts) on an individual user's computer.\par
\par
\par
\b II. Security Model\par
\b0\par
The security model of the use of this application can be modeled as a protocol in which the user "sends to the future" messages that must be confidential and authenticated.\par
\par
\f1  Bob    --------------->    "The Cloud" online storage    --------------->    Bob\par
            Eve                        Eve                     Eve\par
(Eve)                                                                        (Eve)\par
\f0\par
The security "protocol" has the following necessities:\par
1. Bob wishes to store data in an online storage service for an undetermined amount of time.\par
2. Bob may lose all his original copies of data except his secret (key)\par
3. Bob does not want any attacker to capture his data (i.e. confidentiality requirement)\par
4. Bob wants to be sure the data he gets back is the data he uploaded (i.e. authentication requirement)\par
\par
Opportunities from the attacker's point of view:\par
1. Eve can monitor the upload or download link, or modify/insert/delete data in transit, without being detected.\par
2. Eve can read the contents of Bob's online storage without being detected.\par
3. Eve can even change the contents of Bob's online storage without being detected.\par
\par
The protocol must provide confidentiality. As there is no key negotiation, the attack on the key consists in the transmitted data leaking information about the key, attempting chosen plaintext attacks to guess the key (advantageous if part of the key has leaked), or trying to coerce Bob into decrypting ciphertexts that may cause damage, even if Eve does not have the key.\par
\par
The protocol must provide authentication. Bob must be able to verify that the data he downloads is in fact the same data as he uploaded (without having access to the originals, as he may have lost or deleted them). Bob must be able to detect changes Eve makes to data made without knowing the secret, with certain caveats:\par
- If Bob can retain \i some\i0  local information, specifically the archive manifest, he can detect all changes made to data outside of his local computer.\par
- If Bob can't retain \i any\i0  local information except his secret, he can detect inconsistencies in stored archives, but not total version rollback or deletion.\par
- The protocol cannot protect Bob against data destruction. If Eve or the online storage service destroy all of Bob's files, they are lost. He can only detect this with additional local information (specifically, some record or memory of which files existed).\par
\par
In practice, Eve may also have varying degrees of access to Bob's local computer. This is generally outside the purview of protocol design, as it implies it is possible to directly steal Bob's secret. Mitigation is difficult, but the possibility is realistic and will be discussed at length in the subsequent sections.\par
\par
The following realms are not addressed at all by the tool or by this analysis:\par
1. Plausible deniability. The presence of archive files is a pretty good indication that something was stored there. The tool does not provide any features for disguising or embedding the archived data in a plausibly-deniable form. There may exist tools that are capable of doing so, to varying degress. However, it should be noted that the encrypted file content is designed to be indistinguisable from randomness, so the problem is reduced to concealing the naming scheme and lengths of files.\par
2. Anonymity. Online storage accounts coupled with network access logs may make it possible to identify who uploaded or accessed the archive files. It is outside the scope of the tool to address such user identification. Anonymity may be available to varying degrees via other services (e.g. Tor: http://www.torproject.org/ or I2P: http://geti2p.net/ or Freenet: https://freenetproject.org/).\par
\par
\par
\b III. Operational Environment\par
\b0\par
As the program is intended to be used on an individual user's computer, there are a number of concerns that arise.\par
\par
\b III-1. Local Machine Data Access Security\par
\b0\par
Some attacks described below assume that malware has compromised a user's machine. As security on a typical user's machine may be low, it should be noted that once the machine is compromised, the attacker generally has direct access to the user's files and documents, meaning mitigation of tool-specific weaknesses is of limited use - it is unlikely the tool will be attacked if data files can be obtained directly. In a more secure environment, such as one where the user does not run as administrator and local file collections have more restrictive permissions-sets, an attacker may be more hindered, and protections in the tool may be more helpful.\par
\par
\b III-2. Entry of Password\par
\b0\par
The security of the system hinges on the secrecy of the password/passphrase used to protect files. As this is on an individual user's computer, the security is limited by that of the computer, which may be low. Several attacks are available:\par
1. Compromise of the computer by malware, allowing keystroke monitoring\par
2. Compromise of the computer by malware, allowing memory of the program to be raided\par
3. Compromise of the computer by malware, allowing screen image capture\par
4. Side-channel attacks including:\par
4.a. Accoustic recovery of keystrokes for password entry\par
4.b. RF analysis of computer devices or links (such as the wire connecting the computer and keyboard)\par
4.c. Optical, digital, or RF capture of the computer display (a risk if the password is displayed at some point).\par
\par
It should be noted that the program provides the option of supplying the password as a command line argument, potentially exposing it in the display (attack 4.c) or in the memory (attack 2) of the command shell that launches the program.\par
\par
The program provides a mitigation for password in the form of a randomized, randomly-located grid (within the console window) of characters, wherein the user selects each character of the password by entering the row and then column index. This protects against some attacks, in particular 1 and 4a or 4b by themselves. It does not protect against 1, 4a, or 4b in conjunction with 3 or 4c, which would provide the randomized grid along with the keystroke sequence to an attacker.\par
\par
In addition, the current implementation of the randomized grid for password entry is cumbersome to use, so it is unlikely a user will use it. A mouse-based entry scheme (such as that found in Password Safe [Bruce Schneier - https://www.schneier.com/passsafe.html] or on certain tablet computers) would work much better.\par
\par
In the absence of the randomized grid, display-only attacks can be mitigated by the availability of prompting for password entry without displaying it in the console.\par
\par
In general, 2 cannot be mitigated by any practical means, if the computer's security is lax enough to permit malware to be potentially installed. This includes:\par
1. Malware picked up through web-browsing or other zero-day vulnerabilities\par
2. Malware picked up by poor online hygene on the part of the user (i.e. running downloaded programs or programs attached to email messages)\par
3. Physical access, including pre-boot attacks, auto-run attacks by means of USB drives, etc.\par
\par
A variant of 2 above (poor hygene) is that the tool itself can be used against the user. An attacker could craft archives containing malware, send them to the user (via various means, even complete with password), and attempt to socially engineer the user into unpacking the archive and installing/running the contents. The tool can provide no protection against such an attack.\par
\par
Another variant is if the attacker can place malicious archives in the user's online storage, such that the user downloads them, extracts them, and runs the contents. This is mitigated if 1) the attacker does not know the password, and by the fact that 2) files and archives are validated as authentic by a MAC requiring the correct password.\par
\par
Mention should also be made of the option of supplying the password as a command line argument. This is potentially dangerous, beyond causing the password to be displayed in the command shell. In particular, it may encourage users to put the password plaintext in shell script files, making it easy to recover simply by searching the content of files.\par
\par
A final option is the use of keyfiles (possibly themselves protected by password), as is done by some other backup/archiving applications. This provides higher security, conditionally:\par
1. The password-protected keyfile is still vulnerable to attack, especially if the password is weak.\par
2. The keyfile represents another piece of data, which complicates the process of backup - since it must be stored somewhere and backed-up too (but not to the online storage service!); if the keyfile is lost, the archive files are useless.\par
\par
(Discussion of specific operational considerations of keyfiles will be omitted until such time as the tool supports keyfiles.)\par
\par
\par
\b IV. Password/Passphrase and Key Derivation\b0\par
\par
The program relies entirely on a password/passphrase for security. The design of the program means it generally cannot rely on any persistent storage from one run to another. In a backup-restore scenario, after a total loss of the local computer, all that is remains is the saved archive in the online storage system, which must be sufficient (coupled with the password) to restore data. Therefore, it is important that passwords/phrases with sufficient entropy be used. An absolute minimum of 20 characters is recommended.\par
\par
Master key derivation is done by expanding the passphrase and password salt into a master key of 1024 bits by means of the RFC 2898 algorithm. The current set of ciphersuites select 20,000 iterations. A master key of 1024 bits is considered more than adequate because a user password/passphrase is unlikely to approach that degree of entropy, so 1024 bits will sufficiently capture the entropy available in the passworld/phrase. The use of the master key will be discussed in section VI-2-A.\par
\par
Password salt (512 bits) is used to randomize the master keys generated by archives. The password salt is stored in each file of a multi-file archive, but the same value is used across all files of the archive. This does not provide any additional security in the master key, but would foil attacks using precomputed master keys, because it is unlikely that an attacker will have precomputed the master key dictionary with the particular salt being used in a particular archive fileset.\par
\par
The tool supports an option to force unique password salt in each file, at the cost of incurring significant overhead (due to use of RFC 2898) for each file decrypted. This would be a significant cost, for example when decrypting a segmented archive with a large number of small segments. But it can make the program much more resiliant against dictionary (precomputed key) attacks and thereby reduce the required entropy in the password. Although it is supported, due to the cost it is expected that users will not use the option and therefore not receive an benefits from this mode of operation.\par
\par
The master key derivation algorithm is required to be computationally expensive to foil password-guessing attacks. The most significant risk associated with the particular choice in this tool (RFC 2898, which uses SHA-1) is the use of hardware-acceleration in password-guessing. It should be considered to use a more future-resistant derivation scheme, one potential being \i scrypt\i0  (http://www.tarsnap.com/scrypt.html), although as of this writing \i scrypt\i0  may be too new to be fully vetted by the security community.\par
\par
\par
\b V. Supported Ciphersuites\b0\par
\par
\b V-1. Block Ciphers\b0\par
\par
The tool currently supports the following ciphersuites:\par
- AES-256 (Rijndael; 128 bit block size), plus HMAC-SHA2-512-256 (SHA2-512 truncated to 256 bits) for authentication\par
- Serpent-256 (128 bit block size), plus HMAC-SHA2-512-256 (SHA2-512 truncated to 256 bits)  for authentication\par
- ThreeFish-1024 (1024 bit block size), plus HMAC-Skein-1024-512 (Skein-1024 truncated to 512 bits) for authentication\par
\par
The set of ciphersuites was chosen to be small but functional. In particular, the program designer regarded it as risky to provide too many options because of the increase in size of test matrix and because it is difficult for a user to know how to choose an option. The three options are considered individually here:\par
\par
\ul AES-256\ulnone\par
\par
The AES standard is showing it's age. A number of attacks have been mounted compromising most of the rounds. Some cryptographers are suggesting that new uses of AES should increase the number of rounds, but there is no agreement. The risk is that AES may become vulnerable in a relatively short amount of time.\par
\par
\i TODO: redo this section\par
\i0 In addition, AES-128 with a 128 bit key only provides a marginal security margin against brute-force attacks these days. Unfortunately, the version of AES with 192 or 256 bit keys is seen as weak due to a weak key schedule, and therefore not buying anything over AES-128 (see https://www.schneier.com/blog/archives/2009/07/another_new_aes.html).\par
//\par
In more detail, because of the birthday bound problem (which says, given a key of 2^(n) length, key-reuse collisions can be expected after observing only approx. 2^(n/2) messages), a 128-bit key in general only provides a 64-bit level of security against brute-force attacks. This is a theoretical argument, but a number of real attacks are based on it. It is generally accepted that computing power is reaching the point where 64-bit security is not sufficient.\par
\par
TODO: discuss AES-256 with weak key schedule attack and why random key selection mitigates against related-key attacks.\par
\par
The implementation of AES (Rijndael) used is provided by the .NET Framework (minimum 2.0), which wraps the Windows CryptoAPI library.\par
\par
\ul Serpent-256\ulnone\par
\par
Serpent has a higher margin of security, but at a cost to performance (which is the most likely reason why it didn't win the AES competition). Performance may be an issue for large amounts of file data, but as the tool is meant to be used offline this may be acceptable to users. The provision of an option with a 256-bit key helps give a reasonable option for obtaining a 128-bit level of security.\par
\par
The implementation of Serpent was taken directly from the designers (see http://www.cl.cam.ac.uk/~rja14/serpent.html and http://www.cs.technion.ac.il/~biham/Reports/Serpent/). In particular, this is a straight-forward transliteration of the "bitsliced" variant, in java, from the submission archive (http://www.cl.cam.ac.uk/~rja14/Papers/serpent.tar.gz). The original java version was created by Cryptix. There is a very small risk that the implementation got broken in a subtle way during porting, but it is highly unlikely. There is a suite of test vectors available in the application source, which passed. Also, a short selection of test vectors are checked every time the application runs, and any problem introduced (most likely it would be due to arithmetic differences between java and C# syntax) would be caught.\par
\par
\ul ThreeFish-1024\ulnone\par
\par
ThreeFish was chosen to provide a very long key length and cipher block length, as well as a very long hash length, in it's incarnation as Skein. In this application, 1024-bit keys and block lengths are used for all these. Since Skein was an entry in the NIST SHA-3 competition, it underwent some analytical scrutiny. However, it was not selected for the standard and so draws only modest analytical attention vs. standardized algorithms. Therefore, any weaknesses may go undetected for a long time.\par
\line The ThreeFish implementation was created by Alberto Fajardo and is publicly available (here: http://code.google.com/p/skeinfish/, see also: https://www.schneier.com/skein.html, https://www.schneier.com/threefish.html, and https://www.schneier.com/code/skein.zip). As the implementation is already in C#, it was incorporated into the tool with no changes. There is very little risk that it was broken in the process of incorporating.\par
\par
\b V-2. Hash and HMAC\b0\par
\par
The HMAC-SHA2-512-256 construction used for authentication (validation of key and data) has so far withstood attacks well. This one is used in the AES and Serpent ciphersuites.\par
\par
The generic HMAC primitive is implemented in the source code of the tool. The implementation of SHA2-512 used is provided by the .NET Framework (minimum 2.0), which wraps the Windows CryptoAPI library.\par
\par
The HMAC-Skein-1024 construction (used in the ThreeFish ciphersuite) has not been validated due to a lack of publicly available test vectors, other than a very brief self-test in the Skein module. In fact, the HMAC-Skein-1024 construction has some risk to it, mainly due to it's novelty. HMAC is well-respected at this point. Skein was designed to be strong, and underwent scrutiny as part of the NIST SHA-3 competition (it was not selected). Since Skein is not a standard, it draws only modest analytical attention vs. standardized algorithms. Therefore, any weaknesses may go undetected for a long time.\par
\par
\b V-3. Cryptographic Random Number Generation\b0\par
\par
The random number generator used by the tool is the default random number generator provided by the .NET Framework (minimum 2.0) which wraps the Windows CryptoAPI library, via the RNGCryptoServiceProvider class, with the default constructor. Nothing is known about this random number generator and no attempt is made to validate it's proper functioning. This could pose a risk if the system's underlying random number generator turns out to be weak (either by implementation flaw or by being weak or outdated).\par
\par
The risk posed by a bad system-provided random number generator could be mitigated by implementing a separate random number generator (with validation), (for example, Fortuna: https://www.schneier.com/fortuna.html), and periodically incorporating input from the system-provided random number generator into it's seed to take advantage of any real-time entropy being accumulated by the system's implementation.\par
\par
\i TODO: some information is available here: http://en.wikipedia.org/wiki/CryptGenRandom\par
perform analysis and summarize details.\i0\par
\b\par
V-4. General Comments on Correctness\b0\par
\par
The tool runs a small set of test vectors for each cryptographic primitive every time it starts. If, for some reason, an implementation becomes broken, the tool will fail to start with an error message indicating which primitive failed it's self-test. It is remotely possible but highly unlikely for a systematic change (e.g. .NET version change, compiler change, machine architecture change, etc) to break a primitive in a way that it still passes it's self-test.\par
\par
\ul The following primitives self-test every launch:\ulnone\par
HKDF-SHA2-512 (key expansion and extraction)\par
HMAC-SHA2-512-256\par
AES\par
Serpent\par
Skein (in a very basic way)\par
ThreeFish (in a very basic way, by virtue of it underlying Skein)\par
CTR-mode block cipher composition (see section VI-2-B)\par
\par
\ul The following primitives do not self-test:\ulnone\par
SHA2-512\par
HMAC-SHA2-512-256 (mitigated by the fact that HMAC-SHA2-256 does self-test)\par
Default cryptographic random number generator (.NET system-provided)\par
HMAC-Skein-1024 (due to a lack of publicly confirmed test vectors)\par
\par
\ul Notes:\par
\ulnone ThreeFish and Skein in their 1024-bit configurations are only tested in a very limited way\par
\par
\b\i TODO: verify this section's claim via code coverage report\par
\b0\i0\par
One final implementation risk at this level is that the cryptographic primitives are being used improperly by the tool.\par
\par
\b\i TODO: *how to gain confidence, or mitigate the potential of misuse\par
\b0\i0\par
See section VII for further discussion of implementation correctness.\par
\par
\par
\b VI. Implementation of Encryption Over Program Functionality\b0\par
\par
\b VI-1. Decremental Checkpoint Mode\b0\par
\par
Encryption is available for the decremental checkpoint mode (making fast backups). In this scenario, each individual file is encrypted. In addition, there is a magic file (check.bin or checkc.bin) located in the archive root with a known content that is used to validate the password.\par
\par
The encrypted portion of the check file contains a salt value (same size as the per-file salt value) before the fixed bytes that are checked, to foil attacks against the known plaintext. This salt is in addition to a per-file salt that ensures (probabilistically, see section VI-2-A) that the file does not share a key with other files.\par
\par
The cipher key and signing key differ for each file, but they are derived from the master key (derived from the password), so if an attacker can gain the password or master key, he can gain \i all \i0 of the files in an archive.\par
\par
The primary weakness of this mode of operation for the tool is that all individual files are stored separately, so an attacker has full access to 1) the names of files, 2) the directory hierarchy of the archive, 3) the lengths of files, and 4) what changed from one checkpoint to the next. This is considered a large amount of information, with the following attacks:\par
1. The file naming and size directly leaks information about what domain the user's data files apply to, and may include detailed specific information within that domain that could meet the definition of a successful attack (e.g. in an industrial espionage scenario, it may be possible to know quite a lot about specific implementation decisions being made in engineering a product, such as selected algorithms known from source code file names).\par
2. By knowing the file names and hierarchy, it is easy to identify known plaintexts. For example, if the C:\\ drive of a Windows computer is backed up, many of the files in the archive will be system files with well known content. In some uses, there could be a simply massive amount of this known-plaintext data available to an attacker. This could facilitate attempts to gain the key by comparing plaintext and ciphertext versions of a file.\par
3. Full integrity is not provided for this archive mode (see section VI-2-C).\par
\par
In general, it is not recommended to use encryption with the decremental checkpoint backup usage of the tool, because it leads to a false sense of security. The mode should be disabled in the tool. A much safer solution for this particular problem is to use a disk-level encryption utility to encrypt the entire volume containing the archive.\par
\par
Note that the per-file encryption scheme used in the decremental checkpoint backup facility is reminiscent of Windows NTFS encrypted file system (EFS, see http://technet.microsoft.com/en-us/library/cc700811.aspx). However, the tool's scenario is weaker than EFS because all files use the same key and there are no system-provided permissions-based access limitations on the files.\par
\par
\b VI-2. Encrypted File Container Structure\b0\par
\par
\b VI-2-A. Per-File Key Derivation\b0\par
\par
Recall from section IV that the password/passphrase is used to derive a 1024-bit master key, via RFC 2898 and 20,000 rounds, and password salt (shared across files of an archive). The master key is not used directly, but seeds a further key derivation process to derive a unique key for each file being encrypted, even if the same password is used for multiple files. This decouples the password and file key. The process has the following properties:\par
1. The derivation of the master key not is susceptible to dictionary attacks where RFC 2898 has been precomputed, due to the password salt.\par
2. The derivation of the file key from the master key is not compute-intensive, therefore given a master key, it is fast to determine a file key and see whether it is decrypts the file.\par
3. If a file key is compromised by a known-plaintext attack (for example, see section VI-1), it is \i difficult\i0  to to discover the master key or password.\par
\par
In fact, two keys are derived for each file: a cipher key and a signing key for use with the MAC function (and a third value is derived, the initial counter value; see VI-2-B). The size of the cipher key depends on the ciphersuite used:\par
- 256 bits for AES-256\par
- 256 bits for Serpent-256\par
- 1024 bits for ThreeFish-1024\par
The size of the signing key depends on the MAC function used:\par
- 1024 bits for HMAC-SHA2-512-256\par
- 1024 bits for HMAC-Skein-1024\par
\par
See section V-1 for a discussion of key lengths and security.\par
\par
The keys are derived using HKDF-SHA2-512, which provides an extract function for turning the pseudorandom master key into a (practically) arbitrary number of bits for derived key material. The HKDF extract function requires random salt, which exists on a per-file basis. That file salt is stored at the beginning of each file (after the shared password salt), and is a 1024-bit string of random bits, generated by the random number generator (see section V-3). This amount of salt should more than enough randomness for all foreseeable applications and revisions of this tool.\par
\par
HKDF-SHA2-512 is considered secure at this time, and therefore should be adequate for the foreseeable future.\par
\par
\b VI-2-B. Cipher Mode of Operation\b0\par
\par
The stream encryption is achieved by operating the underlying block cipher in CTR (counter) mode. Conceptually, CTR mode creates a one-time-pad (OTP) from a key and an initial counter value. An important requirement of CTR mode is that for any given key, no counter value is ever reused, \i forever without restriction\i0 . In typical online secure protocols, the counter can be derived from a nonce (e.g. message sequence number), and the session key derived randomly anew for each session, for security up to the birthday bound on the key length, 2^(n/2). This implementation uses the standard incrementing function for each subsequent OTP block.\par
\par
Since no nonce is available, the initial counter is randomly selected. Theoretically, the possibility of collision becomes realistic at the birthday bound. However, the key is also randomly derived, which has theoretical security to the birthday bound as well. Therefore, the composition of pseudorandom key and pseudorandom initial counter should have theoretical security to at least the birthday bound. It is unclear to me at this time whether there is any advantage beyond the birthday bound of this scheme vs. simply starting all streams with the canonical initial counter value of 1.\par
\par
A risk of using CTR mode is that it needs to be implemented and used properly. We have referred to the best-known issue, that of selecting the initial counter value. In principle, CTR mode is actually the simplest mode to implement (other than ECB), but it is relatively uncommon, which makes it harder to check implementation by examining successful precedents (vs. CBC, which seems to be ubiquitous). However, CTR-mode test vectors are available at least for AES (Rijndael), and the implementation conducts a self-test each time it is booted by running a few CTR-mode test vectors.\par
\par
The use of CTR mode eliminates the need for any padding scheme, so no padding is used. This eliminates any chance of padding attacks.\par
\par
\b VI-2-C. Protecting File Authenticity\b0\par
\par
File authenticity is protected using the HMAC construction, using SHA2-512-256 or Skein-1024-512, depending on the selected ciphersuite, and keyed with a per-file signing key that is HKDF-SHA2-512-derived from the master key and the per-file salt. The MAC thus computed is appended after the stream of ciphertext. The program uses an Encrypt-then-MAC scheme. The MAC is computed over the entire preceding data stream, including the password salt and per-file random salt and the entire ciphertext.\par
\par
One theoretical advantage of using the Encrypt-then-MAC scheme is that it allows streams to be validated (and rejected if invalid) before any encryption is done. This is safest, in particular if there is a possibility of defects existing in the underlying archive management code. Consider the case of a buffer-overrun-with-code-execution defect in the underlying archive parsing code. Assume an attacker figured out how to create a malicious archive that triggers the buffer overrun, without having discovered the keys. If the attacker can convince the user to extract a maliciously prepared archive, he could take advantage of such a defect. If the MAC is validated first before any decryption occurs, this avenue of attack is closed off. Note that in the past, just random data has been enough to trigger some buffer-overruns with code execution. As an example, random ciphertext could produce corrupt archive metadata, causing a buffer overflow. Somewhere else in the ciphertext could be malicious code that ends up residing in a buffer, where it could potentially be invoked as a result of the buffer-overrun-with-code-execution. Since the tool is written in a memory-managed environment with full-time strict data structure bounds checking, it is not expected to be vulnerable to this particular attack. Nonetheless, non-code-execution defects might still exist, such as program crashes or the insertion of files in destructive filesystem locations, such as by corrupting the target file path of an extracted file, if the program's checks to prevent escaping the extract target directory do not work function properly.\par
\par
In practice, validating the MAC requires reading the file twice, once to validate the MAC, and again to decrypt and extract. The default mode of the tool does this, and rejects invalid files without decrypting. However, because of the possibility of a performance penalty, the tool provides (as seems to be typical in today's software) the perhaps ill-advised option to disable MAC pre-check. In this case, the MAC is still checked, but it is computed as the file is decrypted and validated only when the end of the file is reached, after the entire contents of the archive have been decrypted and processed in some way. It should be considered to remove this option.\par
\par
\b VI-3. Special Concerns Around Archives with Multiple Segments\b0\par
\par
\b VI-3A. Authentication and Decremental Backup Archives\b0\par
\par
One attack that the MAC does \i not\i0  protect against is the file-storage analogue of roll-back, replay and re-ordering attacks. In the case of a decremental backup, there is no provision for determining that the right set of files is in fact what is contained in the archive. This permits an attacker with access to the archive storage to:\par
1) overwrite new versions of files with old versions\par
2) swap files around\par
3) overwrite files with the content of other files\par
4) delete files or create new files with content copied from other files\par
5) generally rename, rearrange, or otherwise tamper with the directory hierarchy\par
\line All of this can be done without knowing any keys or passwords. The tool provides no provision for detecting this.\par
\par
\b VI-3B. Authentication and Multi-Segment Archives\b0\par
\par
In the case of multi-segment archives, the tool has features to mitigate this problem. In particular, for any archive, the manifest file contains a nonce used to assign serial numbers to all archive files, including the manifest itself, as well as a randomly chosen 256-bit archive unique identifier. After the MAC is validated on any member of a multi-segment archive, the file can be decrypted to inspect it's segment number. The code implements the following constraints:\par
1. All files in an archive (segments and manifest) must share the same value for the 256-bit archive unique identifier.\par
1. The manifest records the name and serial number of all segments, as well as the current sequence number\par
2. Every segment file must correspond to exactly one entry in the manifest segment table, and it's serial number must match.\par
\par
Every time a segment is rebuilt, it is assigned a new serial number, and the manifest is updated accordingly. No serial number is ever used for more than one value of segment content that existed at any time during the life of the archive.\par
\par
From this, it is possible to detect:\par
1. Segment rollback - the segment's internal serial number will be less than that recorded by the manifest\par
[2. Segment substitution]\par
3. Manifest rollback - the serial numbers in the manifest won't match some of the segments\par
4. Segment deletion - there will be an entry in the manifest for which the file is missing\par
5. Extra segment insertion - there will be a file for which there is no entry in the manifest.\par
\par
The MAC prevents the serial numbers from being tampered with, so the checks above are reliable.\par
\par
In typical usage, users are likely use the same password for multiple archives. Although password reuse is not recommended, it is typical user behavior. In fact, it might seem quite reasonable to a user, after all, it's all his own data, he just wants to archive some subsets of files independently, so why not reuse the password? This gives rise to an attack where an attacker tries to substitute a segment from one archive collection into a different archive collection that had been encrypted with the same password. The attack proceeds as follows:\par
1. The algorithm for assigning serial numbers is public knowledge and predictable. It is likely that the serial numbers of archive segments can be determined if an attacker observes the creation and update sequence of the archive segments, which in some cases is available simply by observing only the communications link or only the sequence of changes made to the online storage service.\par
2. If a second archive exists protected by the same password and with known segment serial numbers numbers, the attacker can substitute a segment from the second archive with serial number \i i\i0  into the first archive for some segment \i i\i0 , and the serial number consistency structure remains undisturbed.\par
This attack is mitigated because the 256-bit archive unique identifier for the foreign segment will not match the unique identifier in the other files.\par
\par
One weakness of the above scheme is that the user can defeat it. In particular, decrypting each segment of an archive individually (without extracting the segment) will expose the plaintext of the segments to modification. The user could then re-encrypt each segment individually, producing a new set of archive files equivalent to the first. This scenario might be realistic if the user wished to change the password of the archive. If an attacker can modify the unencrypted segments before re-encryption, he has full reign to fake the segment serial numbers or the 256-bit archive unique identifier. The resulting segments will validate, giving the appearance that the archive's still has integrity. \i This attack is not mitigated\i0 . It would not be terribly difficult to modify the program to be unable to produce a valid archive by re-encrypting individual the segments. However, if the segments are being stored in plaintext at some point (as required by this attack) and the user's local machine is compromised such that an attacker can then modify those files, there is far more wide-ranging damage that can be done by such an attacker. Therefore, it is not considered useful to mitigate this particular weakness.\par
\par
If the user does not have a local storage option (e.g. in the scenario of total computer failure, with only online storage surviving), then there is a total-archive rollback attack (rollback of manifest and all segments to some previous self-consistent version) that cannot be detected by the user. If the user is able to store most recent manifest offline, then total-archive rollback can be detected by downloading all segments from the online storage and using the offline-saved manifest. Validation will fail because the serial numbers of old (subsequently replaced) segments will not match those stored in the the most recent manifest.\par
\par
A variant of the above attack is an attacker than can delete the user's entire online storage. This can be detected with some saved offline knowledge - if only the knowledge in the user's head that he had something in the online storage which is observed to no longer be there.\par
\par
A final general weakness is that although the "dynunpack" command checks the validity across the collection of archive member files, it is possible to use the "unpack" command on each individual archive (or all, with command line wildcards) which cannot provide any cross-segment checks.\par
\par
\b VI-3C. Leakage in Multi-Segment Archives\b0\par
\par
It has already been determined in section VI-1 and VI-3A that decremental archiving mode leaks an unacceptable amount of information and is not adequately authenticable. This section discusses leaks in multi-segment archive mode.\par
\par
The segmentation algorithm is based on two things: the order of files in the file hierarchy, and the target size of an archive. Two phases need to be examined, initial segmented archive creation and updating an existing segmented archive.\par
\par
Also note from the previous section that users may unpack the archive one file at a time, avoiding cross-file archive integrity checks. It may be difficult to convince a user of the merit of using the safer "dynunpack" vs. the risky "unpack" on each file, especially if performance of the former is worse.\par
\par
\ul Initial segmented archive creation:\ulnone\par
\par
During initial archive creation, the file hierarchy to be archived is scanned and sorted into a canonical order (specifically, culture-invariant alphanumeric sorting). Files are sequentially assigned to segments: a segment is filled with as many consecutive files as will fit while remaining under the target size. If a file would push the segment over the target size, a new segment is started and the file is assigned to the new segment. If an individual file is larger than the target size, it is still assigned to a segment, but the next file gets a new segment, so each "large" file gets it's own segment. In this version of the tool, large individual files are not split across multiple segments.\par
\par
From this we can conclude that it leaks the following information:\par
1. The target segment size can be determined by statistical analysis of the segment sizes. In particular, for an underlying hierarchy of randomly-sized files (with sizes distributed by a power law), there will be an asymmetry in the distribution, with a large number of segments clustering just under the segment size, and a power-law tail of segments exceeding the segment size. The use of data compression would make the data series noiser, but does not diminish the theoretical result.\par
2. Large files will leak their existence by creating a segment larger than the target size. If the attacker knows something about the underlying file hierarchy being processed, the size of the file and the position in the canonical order will make it pretty easy to determine which segment contains the file. Segment assignment is done before the data compression layer; in case data compression is in use, a singleton large file segment may end up compressing smaller than the target segment size, but no additional files are assigned to the segment. Since the compression encoding is public knowledge and could be precomputed by an attacker on the user's underlying fileset, it is still easy to pinpoint the segment containing a particular large file.\par
\par
The foregoing assumes the attacker knows the underlying file structure. If he does not, less information is leaked. However, if the attacker has partial information about the structure of the underlying file, it may or may not be sufficient to determine the identities of some files stored in some segments.\par
\par
All of the foregoing would be useful in mounting chosen-plaintext attacks to attempt key recovery by exploiting weaknesses in the encryption scheme, including cipher weaknesses, key collisions, poorly constructed random salt, improper use or implementation of cryptographic constructions by the tool's author, and so on. In addition, it could be useful in mounting other kinds of attacks, such as segment substitution, in the event a particular segment is known to contain a particular file and the attacker wishes to interfere with the version of the file the user retrieves.\par
\par
\ul Segment updating:\ulnone\par
\par
Periodically, the user will run the tool to incrementally update the segments and resynchronize with the cloud storage (uploading new and changed segments and removing deleted segments). The update algorithm is predictable. The algorithm is summarized as follows. The current file hierarchy is put in canonical order. New files are added to new segments as they occur. Any modified files cause the segment they contain to be updated. Segments that become too large are split. Adjacent segments that can be folded together and still be under the target segment size are folded together. Ranges of moved files are treated as a deletion at the old location and an creation at the new location, with the expected impact on the segment structure.\par
\par
If an attacker has some knowledge of what the underlying file hierarchy is, the pattern of incremental changes to the segments may divulge which files are in which segments. Conversely, by observing the pattern of incremental changes to the segments, it may be possible to deduce things about what is stored in the underlying file structure (such as, is it a collection of email folders, a source repository, a collection if images, etc).\par
\par
There is probably no theoretical way to make precise what specific information is leaked because it depends specifically on the nature of what is being stored in the underlying file hierarchy. However, we can derive a probabalistic relationship: fewer, larger segments will reduce the rate of information leakage to an attacker, but at the cost of more segment rewriting and upload bandwith usage every time an update is made to the archive. More, smaller segments will improve the efficiency of updating the archive and online storage, but at the cost of leaking information about the underlying hierarchy at a faster rate. It is probably an asymptotic relationship, i.e. crudely, R = F/S where R = rate of leakage, S = segment target size, and F = frequency of updates. In the simplest case, an archive that is always a single segment will leak the least amount of information over time, specifically, only the changes in total length of the underlying file collection plus archive metadata.\par
\par
One known attack on large encrypted data stores is based on observing over time what has changed. This attack applies on the segment level, in that an attacker observing the network link or online storage service can determine which segments are being changed and which have remained the same. The attack does not apply \i within\i0  the segment. Each time a segment is regenerated, a new random per-file salt is selected, which changes the cipher key and initial counter. Therefore, the data of the entire file appears to change, even for sections where the plaintext did not change.\par
\par
Overall, it is not known how much damage these forms of leakage might cause, nor how to fully mitigate it. In general, preventing leakage from the pattern of updates to an online storage service is an ongoing research problem (e.g., see: \i The Melbourne Shuffle: Improving Oblivious Storage in the Cloud\i0 , Olga Ohrimenko, Michael T. Goodrich, Roberto Tamassia, Eli Upfal, 2014, http://arxiv.org/abs/1402.5524v1, and references therein).\par
\par
\par
\b VII. Cryptography Suite Implementation\b0\par
\par
\b VII-1. Memory Scrubbing\b0\par
\par
The program as written makes no attempt to scrub or protect memory used to store passwords or keys. The following risks are associated with this:\par
1). Keys or passwords may persist in program memory for a long time. In particular, the garbage collector may leave copies of sensitive data around in areas of memory that end up not being erased/reused, thereby persisting for long periods of time. If there is an attack on the program memory (by malware that can attach as a debugger), these values are at risk of capture.\par
2). Keys or passwords may be paged out to disk if the machine is memory-constrained. An attacker with local execution could force this by overloading the memory system. Malware with reduced privileges (i.e. unable to read user files or access program memory) could still mount such an attack. An attacker without local execution privileges may still be able to coerce system services into excessive memory usage. If, subsequently, the attacker has physical access to the hardware, or there is a system security hole that allows raw disk data to be read from the swap partition, it may be possible to recover keys.\par
3). Keys or passwords persisting in memory may be recoverable if an attacker steals the computer and freezes the memory chips and then accesses them using various well-known forensic techniques.\par
\par
On a typical individual user machine, these attacks are not considered substantial, due to generally wide-ranging damage an attacker can do if the local machine is compromised. The tool was not intended for use in online server applications, but if it is nonetheless put to use in such a scenario, these attack vectors could potentially be more destructive.\par
\par
\i TODO: some memory screening/scrubbing has been implemented. Describe extent and limitation:\par
- archive password and master key\par
- refresh token (and problems with http request/response buffers)\i0\par
\par
\b VII-2. Code Quality\b0\par
\par
The following code quality issues have been identified:\par
\par
In a number of places, byte-vectors are used to store and manipulate keys and random salts. In general, arguments that set or query such properties on cryptographic objects pass the byte-vector objects directly without cloning. It is possible that an object implementing such properties or a caller using such properties could modify the contents of the byte-vector, essentially damaging the reference stored elsewhere, resulting in incorrect operation. A typical failure would result in use of the wrong value for key or salt, producing either an unreadable encrypted file container or failing to decrypt a file given the correct key. These scenarios are programmatically catastrophic (produce unusable output files) but are not security sensitive. No specific instances of this problem have been found. (Note that the .NET Framework cryptographic classes \i do\i0  clone byte-vector arguments and properties.)\par
\par
\par
\b VIII. Implications of Remote Web Access with Dynamic Pack Mode\b0\par
\par
\b VIII-1. Prelude - A General Assessment of Windows Data Protection API\par
\b0\par
The Windows Data Protection API (DPAPI) is used in a number of places below to protect various secrets related to user authentication. It will be useful to keep in mind this short summary of the general functioning and weaknesses of DPAPI during the analysis contained in subsequent sections.\par
\par
DPAPI provides a facility to encrypt application byte streams with an access privilege equivalent to the user's login credential. As it is meant to be unobtrusive as far as the user is concerned, the encryption key is derived from the current user credential (for encrypting new data) and from a current or old user credential (for decrypting existing data). The detailed design can be reviewed here: \ul http://msdn.microsoft.com/en-us/library/ms995355.aspx\ulnone . There has been forensic analysis, reverse-engineering, and attempts at attacks on DPAPI, one of which is described here: \ul http://www.passcape.com/index.php?section=docsys&cmd=details&id=28\ulnone  (which views DPAPI quite favorably).\par
\par
The design of DPAPI has the following implications as far as it is used in this application.\par
\par
1. The access privilege is equivalent to the user's login credential. This means any program that is able to run as the user is able to decrypt data protected with DPAPI. If malware has obtained local execution privilege as user, it will be able to read the content of protected data streams and forge new streams.\par
\par
2. Because the API is designed to be unobtrusive to the user, there is no provision for managing the expiration of keys and protected data. Even if the user changes password or the operating system refreshes the user credential, old data streams can still be decrypted. The operating system does this by retaining all the old login credentials indefinitely, with the following implications:\par
2a. If the operating system's credential protection facility is compromised, it may be possible to decrypt arbitrary protected blobs. It may also be possible to encrypt (forge) new protected streams using old credentials that will be silently accepted by the API.\par
2b. If the user had a weak password for a period of time, all protected streams created during that time are vulnerable to password-guessing attacks on the user's credential, \i even if the user subsequently adopted a stronger password\i0 , because the credential associated with the weak password is retained indefinitely.\par
\par
3. DPAPI may be configured to encrypt data in a way that provides wider access than just the user's logon credential. There may be recovery keys registered with the Windows domain that allow backup/recovery agents to decrypt the data, or IT agents to recover data without need the user's credential. The CRYPTPROTECT_NO_RECOVERY flag that is supposed to prevent recovery keys from being generated, which is appropriate for ephemeral data. However, the flag is essentially undocumented and it is very difficult to verify if the operating system actually honors it.\par
\par
4. DPAPI has been around a while and has used various ciphers in different editions of Microsoft operating systems. Triple-DES was used in earlier versions of Windows XP. It is expected that more recent versions of Windows use AES encryption, but as a rule, Microsoft does not disclose the inner workings of DPAPI. Passcape has disclosed it's forensic reverse-engineering (see link at start of this section); according to them, Windows 7 uses AES-256 in CBC mode.\par
\par
In general, the DPAPI provides moderate security, practically equivalent to being able to break the user's login password, with the additional weaknesses itemized above. For the purpose of the application, this is considered adequate. However, a critical analysis should consider the following guidelines on \i how\i0  DPAPI is used, in order to minimize user remote resource exposure risk. In particular:\par
1. DPAPI should only be used to store ephemeral secrets so that there is a very short window during which compromise of a protected stream can do damage.\par
2. If at all possible, one should avoid writing the encrypted protected streams containing user-related secrets to persistent storage (disk). Inter-process transfer should be done via shared memory (i.e. some mechanism derived from stdio console streams or in-memory pipes).\par
\par
\b VIII-2. Handling User Credentials in OAuth2.0 Authentication Module\par
\b0\par
The supported remote storage services (e.g. Google Drive and Microsoft OneDrive) use the OAuth2.0 protocol to authenticate the user and the client agent software. The general specification of OAuth2.0 can be found here: \ul http://oauth.net/2/\ulnone .\par
\par
Authentication using the client secret is discussed in section VIII-5. The following discussion concerns authentication of the user as remote resource owner.\par
\par
In general, the aim of OAuth2.0 is to separate the authentication of the user as \i remote resource owner\i0  from the \i client agent\i0  (the software that accesses the resources on behalf of the user), resulting in a 3-party system: 1) remote service, 2) resource owner (user), and 3) client agent software. This is a laudable goal, as there is in general no good reason to trust client software. A key implication is that client software is, \i in theory\i0 , not permitted to handle the user's credentials (usually, username and password). Instead, the application must call into a system-provided module where the user logs into his account via a web page interface, using his credentials, and approves specific limited access privileges for the specific application making the request. In a well sandboxed environment (such as, what we hope mobile "apps" will become) this could work well. In a desktop application environment, it makes less sense. In particular, in most cases a desktop client agent is running with the user's credentials and has full access to the desktop operating environment. On most systems today, an application could easily log keystrokes or inspect the memory of the authentication module, thereby obtaining the user's remote credentials, destroying the limitation on remote resource access this protocol is supposed to provide. In particular, the way that both Microsoft and Google (for example) recommend for desktop applications destroys whatever percieved security the protocol offers. Microsoft recommends the use of the WebBrowser control in a System.Windows.Forms managed application for implementing the OAuth2.0 flow (see: \ul http://msdn.microsoft.com/en-us/library/dn631817.aspx\ulnone ). But the application has full access to the internals of the WebBrowser control and could easily obtain the user's remote service password. Even if the WebBrowser control made attempts to prevent it's host from accessing its internals, the application could still attach to itself using the debugging APIs or "unsafe" managed code and inspect the raw memory of the process (WebBrowser is not hosted out-of-process). And as a last resort, the application could install keystroke logging hooks. There is some hope on newer Microsoft operating systems that the UAC mechanism could allow the system to run the application at reduced privileges in order to provide a truly protected WebBrowser login module that the application would be unable to get into, as well as preventing keystroke logging. However, there is no requirement to do so, no clear indication of when it is \i not\i0  happening, and at this time no user expectation of such protection, so this halcyon world is yet some way off. At this point, most users still happily enter their passwords into various applications, no matter how ill-advised, and generally either do not understand the distinctions between various system and application components or have decided (on flimsy evidence) to trust the application and believe that they have given the application itself their credentials.\par
\par
In the desktop scenario as it stands, there is another question: does the application trust the OAuth2.0 web login module? Here, the application contains sensitive user secrets (specifically, the encryption key for the archive). Why should the applciation trust the WebBrowser module? Web browsers have been and continue to be a notorious source of nasty exploits. Web browsers consist of millions of lines of code, constantly changing (in one direction - ever more complicated) as web content becomes ever more sophisticated. It is connecting to a remote web page somewhere with the potential of man-in-the-middle attacks. In general, an application would like to \i not\i0  host a web browser. A properly paranoid application wants to outsource the OAuth2.0 flow to the operating system just as much as the other parties do.\par
\par
In this application, the OAuth2.0 flow is implemented in a separate process, invoked via the executable \i RemoteDriveAuth.exe\i0 . This provides a partial solution to the scenario of not trusting the WebBrowser control. Invocation of the control is in a separate process memory space so exploits against the web browser code are contained in a process other than the one that contains the archive-related secrets (e.g. archive encryption key). This protection is not complete, however. In particular, a code execution exploit in the web browser could allow an attacker to gain local execution privileges as the user, which would potentially facilitate keystroke logging or recovery of the archive-related secrets by attaching to other processes using debugging APIs and extracting keys from the main application process memory space.\par
\par
The implementation here - hosting of the WebBrowser as recommended by Microsoft (in \ul http://msdn.microsoft.com/en-us/library/dn631817.aspx\ulnone ) - has several other flaws, listed below:\par
1. The WebBrowser does not behave the same as official system browser (e.g. "Internet Explorer", "FireFox", or another browser the user may have installed). Here's one particular difference. A paranoid user may select browser configuration settings that erase all temporary state upon shutdown of the browser, including cached files, cookies, other local storage (related to plug-ins, such as Adobe Flash), browsing history, and so on. When hosted as WebBrowser using System.Windows.Forms, the browser \i does not respect these settings\i0 . Therefore, even with cookies being cleared, subsequent reinvocations of \i RemoteDriveAuth.exe\i0  will \i not\i0  ask for the username and password. (In particular, Google; Microsoft always asks for the password, but remembers the username.) There are other protective settings that might potentially be ignored. For example, users may disable plug-ins (such as Adobe Flash). It has not been determined specifically how many settings are relevant and whether, for each of them, in each configuration, they are being honored or ignored in the WebBrowser hosting scenario. It appears to be a large and complex problem.\par
2. The WebBrowser implementation is fairly crude. In particular, there is poor communication of the security state of the remote service. It is hard to tell if SSL/TLS is in use, and there is no provision for checking the certificate in order to verify that the correct services has been reached, rather than some man-in-the-middle spoof.\par
3. All SSL/TLS weaknesses apply to the scenario - in particular, the ease of compromising X.509 certificates or presenting "look-alike" certificates that are convincing upon casual inspection. The implementation relies on WebBrowser to do any certificate revocation checking, which \i may or may not\i0  be ocurring in the hosted scenario.\par
4. The application does not make any attempt to "harden" or protect the WebBrowser as far as eavesdropping of user credentials is concerned. Handling of login web pages by the WebBrowser control is assumed to be equivalent to how it is done in the standard web browser application (such as Internet Explorer). In light of #1, it is unclear whether that is really the case.\par
5. The hosted WebBrowser always invokes the engine from Internet Explorer (sometimes known as Trident or mshtml.dll), even if the user has installed another browser (such as FireFox) and elected that as their preferred browser. This means the user may be running web browsing code that they have decided they do not trust, despite their selections. Furthermore, such a user may have neglected to harden the security settings of Internet Explorer (assuming they are even honored, see #1), as they do not have an expectation that the Internet Explorer code will be used.\par
6. Related to #5 and #1, users who have configured anonymity proxy systems, such as Tor, need to ensure that the system proxy settings in Internet Explorer have been set to communicate via the proxy. In the case of #5, a user may have configured their preferred browser (e.g. FireFox) and neglected to configure Internet Explorer, resulting in direct server connections, contrary to their expectation. Futhermore, it has not been verified that the hosted WebBrowser respected the proxy settings established in Internet Explorer. Finally, even if the proxy settings are respected, there is the possibility that identity-compromising information may be leaked (e.g. from DNS requests or code defects in the browser).\par
7. Related to #6, the developers of Tor consider Internet Explorer to be inadequate; they also consider using the system settings and system browser to be inadequate for anonymity, and have gone to great lengths to proivde a FireFox-based self-contained package. In this scenario, the application is unable to interoperate in an adequate way for privacy. The inability to support anonymity is not considered a severe problem because the supported remote services have a fairly high bar of requiring the user to disclose information about his identity, but it can be envisioned that despite the remote service identity-disclosure requirements there are some useful scenarios which are not supported by the application.\par
\par
\b VIII-3. Transfer and Persistence of Access Tokens from OAuth2.0 Authentication Module\par
\b0\par
\i TODO: mitigation of persistence of refresh token by providing option to not obtain it\i0\par
\par
The last aspect of the OAuth2.0 flow implementation is the extraction of user access tokens from the flow back to the main application process. There are two scenarios provided, first, a simple login flow that returns an access token and optional refresh token, and second, a login flow using a previously obtained refresh token that returns an access token and refresh token.\par
\par
The refresh token is particularly security sensitive because it does not expire.\par
\par
Considering the simpler scenario, the primary challenge is to transfer the obtained access token and refresh token to the main application process. This is done by means of the console standard output stream in the client application. In particular, the following actions are taken:\par
1. The main application launches the authentication flow process and redirects the standard output stream to an in-memory recipient.\par
2. After obtaining the tokens, the authentication flow process encrypts them using DPAPI and writes them to it's standard output.\par
3. The main application decrypts the received output to obtain the tokens.\par
\par
It is expected that the redirection of standard output to the invoking process's in-memory handler prevents any of the transferfed data from being written to disk. It is unclear whether that is guarranteed, in particular, if memory pressure is high, there is the possibility that the system will page out buffers associated with transferring the redirected stream. There are no options for demanding such guarrantees. It may be preferable to use a different mechanism for transferring the token data, such as a pipe, as long as security of the pipe can be assured. In particular, one needs 1) a guarrantee from the system that data in the pipe is never written to disk, and 2) that no processes can access the pipe other than the main application process and the authentication flow process that it specifically launches for a given request.\par
\par
The token data is encrypted with DPAPI, providing protection against it being captured equivalent to breaking the user's login. There is a provision in the API for providing "secondary entropy" (i.e. salt). The authentication flow process generates random salt using RNGCryptoServiceProvider, to a total of 256 bits. (See section V-3 for an assessment of RNGCryptoServiceProvider.) The salt is emitted unencrypted on the output stream before the protected data stream is emitted. In some scenarios, it may be preferable to allow the salt to be passed in as an argument so that it can be omitted from the output stream. In the case where the output stream is written to disk or captured, omitting the salt value would make it impossible to decrypt the protected data (except by brute force) even if the key or user's login credential were compromised, and increase the difficulty of capturing both the salt and encrypted data for debugger-type attacks.\par
\par
The more complex scenario involves exchanging a previously obtained refresh token for an access token. The sequence is as follows:\par
1. The main application launches the authentication flow process and redirects standard output as before.\par
2. The refresh token is passed as an argument to the flow process (encrypted with DPAPI). The (256-bit) salt is also passed as an argument.\par
3. After obtaining the new tokens, the authentication flow process encrypts them and writes them to standard output.\par
3. The main application decrypts the received output to obtain the tokens.\par
\par
The most security-critical part of this sequence is passing the refresh token across the process boundary. The refresh token never expires, so compromising the refresh token implies permanent access to the user's remote resources. The use of DPAPI ensures that at minimum the protection on the refresh token is equivalent to the user's login on the operating system. This does cross a security boundary, the remote resource being protected by a local level of security, which may be a lower level of protection than is normally available for the remote resource. In other words, the remote resource is vulnerable to attacks on the local system.\par
\par
The following risks apply to the handling of the refresh token:\par
- The protected stream may be written to disk in low memory situations, because the shell does not guarrantee that program arguments aren't paged out.\par
- The protected stream and it's salt are passed together, providing a single point of capture in the case of a debugger-type attack involving local user execution privileges. There could be ways of making the attack more difficult, such as by using a different in-memory interprocess communication mechanism, exchanging the salt and encrypted stream in separate steps, or even using a key negotiation protocol to protect the transferred data with forward secrecy, but all such approaches fail to address the fundamental exposure of process memory by means of local execution privileges and debugger-style attacks.\par
\par
\b VIII-4. Transfer and Persistence of Archive Passphrase using UI Authentication Scripting Utility\par
\b0\par
\i TODO: write this section\i0\par
\par
\b VIII-5. Handling of Client Secret in OAuth2.0 Authentication Module\par
\b0\par
\i TODO: write this section\i0\par
\par
\par
\b IX. Summary\b0\par
\par
The tool probably provides adequate security in a single user scenario where it is run securely on an individual's computer and the archive files are moved to an online storage service. Other than the weakness of relying on a password, the encryption scheme provides adequate cryptographic security options now and for the foreseeable future.\par
\par
The tool does not provide high security for individual or online-server applications because of:\par
- the lack of a keyfile option,\par
- the lack of hardening around in-memory keys and passwords\par
\par
End of report.\par
\par
}
 